\documentclass[a4paper, 12pt]{article}
\usepackage[english,russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage[top=0.8in, bottom=0.75in, left=0.625in, right=0.625in]{geometry}

\title{АиСД, пилотный поток. Лекция 5.}
\author{}
\date{}

\begin{document}
\lstset{numbers=left}
    \maketitle
\newcommand{\Expect}{\mathsf{E}}
\subsubsection*{Bucket sort. Карманная сортировка (корзинная сортировка).}
На вход алгоритму подается последовательность $a_1, a_2, \ldots, a_n$. Обозначим $b = min(a_i)$ $\forall i \in \{1, 2,  \ldots , n\}$. Обозначим $c = max(a_i)$ $\forall i \in \{1, 2,  \ldots , n\}$.
При карманной сортировке предполагается, что входные данные равномерно распределены на отрезке [b, c]. Разбиваем отрезок на n корзин, т.е. проводим n-1 границу, где координата i-ой границы = $b+\frac{c-b}{n}\cdot i$.
Будем хранить списки элементов, попавших в каждую корзину. Элемент $a_i$ попадает в $s_i$ корзину, при этом $s_i = \lfloor\frac{a_i-b}{\frac{c-b}{n}}\rfloor$.
Теперь нужно отдельно отсортировать каждую корзину. Например, можно к каждой корзине рекурсивно применить bucket sort. Если числа распределены на отрезке не равномерно, то время работы алгоритма может быть O($n^2$).

Предположим, что последовательность состоит из целых чисел от 0 до u-1. Проанализируем, сколько шагов может быть сделано алгоритмом. Заметим, что каждый раз диапазон b и c уменьшается хотя бы вдвое. То есть $c'-b'\leqslant \frac{c-b}{2}$.
Из чего следует,что шагов будет сделано не больше, чем $n \log_2{n}$, тогда время работы можно оценить как $O(n \log n)$.
На практике числа раскидывают по корзинам один раз, а дальше внутри каждой корзины вызывается более простой алгоритм сортировки, например, быстрая сортировка.

Пусть  $a_1, a_2, \ldots, a_n$ --- последовательность случайных чисел от 0 до u-1. Докажем, что в этом случае алгоритм (одна итерация bucket sort, а затем сортировка каждой корзины пузырьком) имеет время работы O(n).

$t(n) = an + \sum\limits_{i=1}^{n}b\cdot s_i^2$, где $s_i$ --- количество элементов в корзине i, b --- константа.
Нужно оценить:
$\Expect \sum\limits_{i=1}^{n}b\cdot s_i^2 = b\sum\limits_{i=1}^{n}\Expect s_i^2$.
Введём $p_i$ --- номер корзины i-го элемента.
 $b\sum\limits_{i=1}^{n}\Expect s_i^2 = b\sum\limits_{i=1}^{n}\Expect\sum\limits_{j=1}^{n} \left(I(p_j = i)\right)^2 = b\sum\limits_{i=1}^{n}\Expect\sum\limits_{x=1}^{n}\sum\limits_{y=1}^{n} \left(I(p_x = i \ and \ p_y = i)\right) = $
$ b\cdot \Expect\sum\limits_{x=1}^{n}\sum\limits_{y=1}^{n} \left(I(p_x = p_y)\right) = b\cdot \sum\limits_{x=1}^{n}\sum\limits_{y=1}^{n} \Expect\left(I(p_x = p_y)\right) = \\ b\cdot \sum\limits_{x=1}^{n}\sum\limits_{y=1}^{n}\frac{1}{n} = b\cdot n$

\subsubsection*{Сортировка во внешней памяти.}

HDD обладает таким свойством: на поиск нужной ячейки тратится гораздо больше времени, чем на время чтения данных из нее. На то, чтобы считать последовательный фрагимент длины x, мы затрачиваем $l+\frac{x}{s}$, где l --- это latency, s --- speed (насколько быстро происходит чтение данных).

Считывание с диска происходит пакетами размера $b$. Желательно  $l \approx \frac{b}{s}$. Размер оперативной памяти = M.

Merge sort во внешней памяти. Всегда используются последовательные доступы к памяти. Массив разбивается на два блока, которые рекурсивно сортируются. За сколько можно реализовать merge, если данные хранятся во внешней памяти? Первым шагом подгружаем два блока по b элементов из каждой последовательности.
Считаем, что оперативная память может вместить несколько блоков размера b. Заводим блок результата, а также место в HDD, куда будет записан массив после merge. Если заполняется блок результата, то записываем данные в HDD. Если заканчиваются элементы в блоке одной из последовательностей, то подгружаем следующий блок.
Сколько операций чтения и записи блока будет совершено? Игнорируем количество сделанных процессором действий, учитываем только запросы к жесткому диску. Таких запросов будет $\frac{2n}{b}$ для одного merge. Весь алгоритм работает за $O(\frac{n}{b} \log n)$.

Улучшим время работы. Как только длина текущего фрагмента стала меньше, чем размер свободной ОП, загружаем его в ОП и сортируем. Время работы $O(\frac{n}{b} \log \frac{n}{M})$. Следующая идея заключается в том, что можно делать multimerge, т.е. делить массив не на два фрагмента, а на k фрагментов, $k = \frac{M}{b}$.
Тогда время работы алгоритма $O(\frac{n}{b} \log_{\frac{M}{b}}\frac{n}{M})$.


\end{document}
